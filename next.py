import os
import pandas as pd
from bs4 import BeautifulSoup

# 1. selector ë¶ˆëŸ¬ì˜¤ê¸°
selector_path = "crawl_result/selector.txt"
if not os.path.exists(selector_path):
    print("âŒ selector.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit()

with open(selector_path, "r", encoding="utf-8") as f:
    selector = f.read().strip()

# 2. ìë™ ì¶•ì•½
parts = [p.strip() for p in selector.split(">")]
if len(parts) > 2:
    short_selector = " > ".join(parts[-2:])
    print(f"ğŸ“¦ ì„ íƒì ìë™ ì¶•ì•½ ì ìš©: {short_selector}")
else:
    short_selector = selector
print(f"ğŸ” ìµœì¢… ì ìš© ì„ íƒì: {short_selector}")

# 3. í‚¤ì›Œë“œ í•„í„°
use_keyword_filter = input("ğŸ” íŠ¹ì • í‚¤ì›Œë“œ í•„í„°ë¥¼ ì ìš©í• ê¹Œìš”? (Y/N): ").strip().lower()
filter_mode = "none"
keywords = []

if use_keyword_filter == "y":
    filter_mode = input("âœ… í¬í•¨í• ê¹Œìš”(I) ì œì™¸í• ê¹Œìš”(E)? (I/E): ").strip().lower()
    raw = input("ğŸ“Œ í‚¤ì›Œë“œ ì…ë ¥ (ì‰¼í‘œë¡œ êµ¬ë¶„): ").strip()
    keywords = [kw.strip() for kw in raw.split(",") if kw.strip()]
    print(f"ğŸ¯ ì ìš© í‚¤ì›Œë“œ ({'í¬í•¨' if filter_mode == 'i' else 'ì œì™¸'}): {keywords}")

# 4. í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
use_length_filter = input("ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œì„ ë‘˜ê¹Œìš”? (Y/N): ").strip().lower()
min_len, max_len = 0, 9999
if use_length_filter == "y":
    min_len = int(input("ğŸ”¢ ìµœì†Œ ê¸€ì ìˆ˜ ì…ë ¥ (ì˜ˆ: 10): ").strip())
    max_len = int(input("ğŸ”¢ ìµœëŒ€ ê¸€ì ìˆ˜ ì…ë ¥ (ì˜ˆ: 50): ").strip())
    print(f"ğŸ“ ì ìš© ê¸¸ì´ ë²”ìœ„: {min_len} ~ {max_len}ì")

# 5. CSV íŒŒì¼ ë¡œë“œ
csv_files = [f for f in os.listdir("crawl_result") if f.startswith("result_") and f.endswith(".csv")]
if not csv_files:
    print("âŒ result_*.csv íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    exit()

csv_files.sort(reverse=True)
csv_path = f"crawl_result/{csv_files[0]}"
print(f"ğŸ“„ ëŒ€ìƒ CSV íŒŒì¼: {csv_path}")
df = pd.read_csv(csv_path)

# 6. ì •ì œ ë° í•„í„°ë§
filtered_set = set()

# âœ… fallback ì„ íƒì ë¦¬ìŠ¤íŠ¸ (ê°€ì¥ ë¨¼ì € ì„±ê³µí•œ selector ì‚¬ìš©)
fallback_selectors = [short_selector, "strong.cnf_news_title", "a.cnf_news_area"]

for html in df["ë‚´ìš©"]:
    try:
        soup = BeautifulSoup(f"<div>{html}</div>", "html.parser")
        matches = []

        # fallback selector ìˆœì°¨ ì ìš©
        for sel in fallback_selectors:
            matches = soup.select(sel)
            if matches:
                break

        for elem in matches:
            text = elem.get_text(strip=True)
            if not text:
                continue
            if not (min_len <= len(text) <= max_len):
                continue
            if filter_mode == "i" and not any(kw in text for kw in keywords):
                continue
            if filter_mode == "e" and any(kw in text for kw in keywords):
                continue
            filtered_set.add(text)
    except:
        continue

# 7. ì €ì¥
output_path = "crawl_result/title_only.csv"
pd.DataFrame(sorted(filtered_set), columns=["ì œëª©"]).to_csv(output_path, index=False, encoding="utf-8-sig")

print(f"\nâœ… ì •ì œ ì™„ë£Œ: {len(filtered_set)}ê°œ ê³ ìœ  ì œëª© ì¶”ì¶œë¨")
print(f"ğŸ“ ì €ì¥ ì™„ë£Œ: {output_path}")
