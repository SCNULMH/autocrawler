from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
import time
import csv
import os

# ğŸ”§ í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
service = Service('./chromedriver.exe')
options = Options()
options.add_argument('--start-maximized')
driver = webdriver.Chrome(service=service, options=options)

# 1. í˜ì´ì§€ ì ‘ì†
url = input("í¬ë¡¤ë§í•  ì‚¬ì´íŠ¸ URL ì…ë ¥: ")
if not url.startswith("http"):
    url = "https://" + url
else:
    url = url
driver.get(url)
print(f"âœ… í˜ì´ì§€ ì ‘ì† ì™„ë£Œ: {url}")
time.sleep(2)

# 2. í‚¤ì›Œë“œ or í´ë¦­ìœ¼ë¡œ ìˆ˜ì§‘ ëŒ€ìƒ ì§€ì •
use_keyword_search = input("ğŸ“Œ í‚¤ì›Œë“œë¡œ HTML ìš”ì†Œë¥¼ ê²€ìƒ‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (Y/N): ").strip().lower()
if use_keyword_search == 'y':
    keyword_text = input("ğŸ” ì…ë ¥í•  í‚¤ì›Œë“œ (ìš”ì†Œ ì•ˆ í…ìŠ¤íŠ¸ ì¼ë¶€): ").strip()
    matched_elements = driver.find_elements(By.XPATH, f"//*[contains(text(), '{keyword_text}')]")
    if not matched_elements:
        print("âŒ í•´ë‹¹ í‚¤ì›Œë“œë¥¼ í¬í•¨í•œ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        driver.quit()
        exit()
    target_elem = matched_elements[0]
    print(f"âœ… ì²« ë²ˆì§¸ ë§¤ì¹­ ìš”ì†Œ: <{target_elem.tag_name}>")
else:
    print("\nğŸ–±ï¸ ìˆ˜ì§‘í•  í…ìŠ¤íŠ¸ ìš”ì†Œë¥¼ í´ë¦­í•œ í›„ ì½˜ì†”ì—ì„œ ì—”í„° â–¶ï¸")
    input("âœ”ï¸ í´ë¦­ ì™„ë£Œ í›„ Enter â–¶ ")
    target_elem = driver.switch_to.active_element
    print(f"ğŸ“ í´ë¦­í•œ ìš”ì†Œ í…ìŠ¤íŠ¸: {target_elem.text.strip()}")

# 3. ë°˜ë³µ ë¸”ë¡ ìë™ íƒìƒ‰
def find_repeating_parent(element):
    for _ in range(10):
        try:
            class_name = element.get_attribute("class")
            tag_name = element.tag_name
            if class_name:
                class_part = class_name.split()[0]
                selector = f"{tag_name}.{class_part}"
                matches = driver.find_elements(By.CSS_SELECTOR, selector)
                if len(matches) >= 2 and tag_name in ["div", "li", "section", "article"]:
                    return selector
            element = element.find_element(By.XPATH, "..")
        except:
            break
    return None

block_selector = find_repeating_parent(target_elem)
if not block_selector:
    print("âŒ ë°˜ë³µ êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    driver.quit()
    exit()
print(f"âœ… ë°˜ë³µ ë¸”ë¡ CSS ì„ íƒì: {block_selector}")

# 4. í•„í„° í‚¤ì›Œë“œ ë° ì„¤ì •
keyword = input("ğŸ” í•„í„°ë§í•  í‚¤ì›Œë“œê°€ ìˆë‹¤ë©´ ì…ë ¥ (ì—”í„°=ì „ì²´ ìˆ˜ì§‘): ").strip()
max_count_input = input("ğŸ“¦ ìˆ˜ì§‘í•  ìµœëŒ€ ê°œìˆ˜ ì…ë ¥ (ì—”í„°=ë¬´ì œí•œ): ").strip()
max_count = int(max_count_input) if max_count_input.isdigit() else None
field_name = input("ğŸ“„ ì €ì¥í•  ì»¬ëŸ¼ëª… ì…ë ¥ (ì˜ˆ: ë‚´ìš©): ").strip() or "ë‚´ìš©"

# 5. ìˆ˜ì§‘ í•¨ìˆ˜
collected = []

def collect_from_current_page():
    elements = driver.find_elements(By.CSS_SELECTOR, block_selector)
    for elem in elements:
        try:
            text = elem.text.strip()
            if keyword and keyword not in text:
                continue
            if text not in collected:
                collected.append(text)
                print(f"âœ… ìˆ˜ì§‘: {text[:60]}")
            if max_count and len(collected) >= max_count:
                return
        except:
            continue

# 6. í˜ì´ì§€ ìˆ˜ì§‘ ë£¨í”„
page = 1
while True:
    print(f"ğŸ“„ í˜ì´ì§€ {page} ìˆ˜ì§‘ ì¤‘...")
    collect_from_current_page()
    if max_count and len(collected) >= max_count:
        break

    try:
        next_btn = driver.find_element(By.XPATH, '//li[@class="next"]/a')
        next_btn.click()
        page += 1
        time.sleep(2)
        continue
    except:
        print("ğŸ”½ Next ë²„íŠ¼ ì—†ìŒ. ìŠ¤í¬ë¡¤ ë‹¤ìš´ ì‹œì‘...")
        last_height = driver.execute_script("return document.body.scrollHeight")
        while True:
            driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
            time.sleep(1.5)
            new_height = driver.execute_script("return document.body.scrollHeight")
            if new_height == last_height:
                break
            last_height = new_height
            collect_from_current_page()
            if max_count and len(collected) >= max_count:
                break
        break

# 7. ê²°ê³¼ ì €ì¥
os.makedirs("crawl_result", exist_ok=True)
file_name = f"crawl_result/result_{int(time.time())}.csv"
with open(file_name, "w", encoding="utf-8", newline="") as f:
    writer = csv.writer(f)
    writer.writerow([field_name])
    for item in collected:
        writer.writerow([item])

print(f"\nâœ… ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(collected)}ê°œ í•­ëª©")
print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {file_name}")
driver.quit()
